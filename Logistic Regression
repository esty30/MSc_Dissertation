import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt
import os
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Function to convert HbA1C values from percentage to mmol/mol
def convert_hba1c_to_mmol(value, unit):
    # Convert HbA1C from percentage to mmol/mol if needed.
    # If already in mmol/mol, return the original value.
    if unit == "percentage":
        return 10.929 * (value - 2.15)  # Formula to convert percentage to mmol/mol
    return value  # Return the value as is if it's already in mmol/mol

# Function to calculate years with diabetes
def calculate_years_with_diabetes(year_of_diagnosis, current_year=2022):
    # Calculate the number of years a patient has lived with diabetes
    return current_year - year_of_diagnosis

# Load and prepare the data by merging, filling missing values, and converting HbA1c values
def load_and_prepare_data(combined_file, baseline_file):
    # Load the combined and baseline data, merge them, convert HbA1c units, 
    # and handle missing values. Also, one-hot encode categorical variable (technique to convert category into numerical)
    combined_data = pd.read_csv(combined_file)
    baseline_data = pd.read_csv(baseline_file)
    
    # Merge the datasets on 'Hypometrics_ID'
    merged_data = pd.merge(combined_data, baseline_data, on='Hypometrics_ID', how='inner')

    # Ensure hba1c values are numeric and convert percentage values to mmol/mol
    merged_data['hba1c'] = pd.to_numeric(merged_data['hba1c'], errors='coerce')  # Ensure HbA1c is numeric
    
    # Apply the conversion from percentage to mmol/mol where necessary based on 'hba1c_unit'
    merged_data['hba1c'] = merged_data.apply(lambda row: convert_hba1c_to_mmol(row['hba1c'], row['hba1c_unit']), axis=1)

    # Now fill missing HbA1c values with the mean after conversion if missing 
    hba1c_mean = merged_data['hba1c'].mean()
    merged_data['hba1c'] = merged_data['hba1c'].fillna(hba1c_mean)

    # Calculate years with diabetes
    merged_data['years_with_diabetes'] = merged_data['year_of_diagnosis'].apply(calculate_years_with_diabetes)

    # Create binary columns for symptomatic cases and progression
    merged_data['symptomatic_binary'] = merged_data['Number_of_symptomatic_3_9'].apply(lambda x: 1 if x > 0 else 0)
    merged_data['progressed_binary'] = (merged_data['Progressed'] == 'Progressed').astype(int)

    # One-hot encode categorical variables (sex, race, diabetes type, glucose monitoring)
    merged_data = pd.get_dummies(merged_data, columns=['sex', 'race', 'diabetes_type', 'glc_monitoring'], drop_first=False)

    # Drop reference categories to avoid multicollinearity
    merged_data.drop(columns=['sex_Female', 'race_White', 'diabetes_type_Type 1', 'glc_monitoring_CGM'], inplace=True)

    return merged_data

# Function to check for multicollinearity using Variance Inflation Factor (VIF)
def check_multicollinearity(X):
    # Calculate and print VIF scores for the predictors in the model.
    X = X.astype(float)  # Ensure all data are floats for VIF calculation
    vif_data = pd.DataFrame()
    vif_data["feature"] = X.columns
    vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
    print("VIF scores:\n", vif_data)  # Print the VIF scores to check for multicollinearity

# Function to fit logistic regression models and visualise the results
def fit_and_visualise_logistic_regression(data, predictors, outcome, output_dir, model_name):
    # Fit a logistic regression model and generate a visualisation of the results.
    X = data[predictors].astype(float)  # Ensure predictor variables are floats
    X = sm.add_constant(X)  # Add a constant term (intercept) to the model
    y = data[outcome].astype(float)  # Ensure the outcome variable is numeric

    try:
        # Fit the logistic regression model
        model = sm.Logit(y, X).fit(disp=0, method='bfgs', maxiter=200)
        
        # Create a summary table with coefficients, odds ratios, p-values, and confidence intervals
        summary_df = pd.DataFrame({
            'Coefficient': model.params.round(3),  # Round coefficients to 3 decimal places
            'Odds Ratio': np.exp(model.params).round(3),  # Convert coefficients to odds ratios and round to 3dp
            'P-value': model.pvalues.apply(lambda x: '<0.01' if x < 0.01 else round(x, 3)),  # Adjust p-value rounding
            'CI 2.5%': model.conf_int()[0].round(3),  # 2.5% confidence interval lower bound, rounded
            'CI 97.5%': model.conf_int()[1].round(3)  # 97.5% confidence interval upper bound, rounded
        })

        # Create a visualisation of the summary table as an image
        fig, ax = plt.subplots(figsize=(12, len(predictors) * 0.4 + 2))
        ax.axis('off')  # Turn off the axis display
        table = ax.table(cellText=summary_df.values, colLabels=summary_df.columns, 
                         rowLabels=summary_df.index, loc='center', cellLoc='center')
        table.auto_set_font_size(False)  # Disable automatic font size adjustment
        table.set_fontsize(8)  # Set the font size of the table
        table.scale(1, 1.4)  # Adjust the table scale for better readability
        plt.title(f'Logistic Regression Results for {model_name}', fontsize=12, fontweight='bold')

        # Save the table as an image file
        output_file = os.path.join(output_dir, f'log_reg_results_{model_name}.png')
        plt.savefig(output_file, bbox_inches='tight')
        plt.close()  # Close the plot to free memory
        print(f"Results for {model_name} saved to {output_file}")
        return model  # Return the fitted model

    except Exception as e:
        print("An error occurred during model fitting:", e)  # Handle errors during model fitting
        return None

# Main function to run the data processing and modelling
def main():
    base_dir = '/home/ej121/dissertation_part3/level1_log_reg/'
    combined_file = os.path.join(base_dir, 'combined_hypo_summary.csv')
    baseline_file = os.path.join(base_dir, 'Trial_baseline_characteristics.csv')
    output_dir = os.path.join(base_dir, 'new_log_reg_results')
    os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist

    # Load and prepare the data for modelling
    data = load_and_prepare_data(combined_file, baseline_file)

    # Standardise numerical variables for the model (age, hba1c, years with diabetes)
    data[['age', 'hba1c', 'years_with_diabetes']] = data[['age', 'hba1c', 'years_with_diabetes']].apply(lambda x: (x - x.mean()) / x.std())

    # Define the common predictors used in both unadjusted and adjusted models
    common_predictors = ['symptomatic_binary', 'age', 'sex_Male', 'sex_Other', 'race_Black', 
                         'race_Asian', 'race_Other', 'diabetes_type_Type 2', 'glc_monitoring_Flash', 
                         'glc_monitoring_SMBG', 'years_with_diabetes', 'hba1c']

    # Check for multicollinearity among the predictors
    check_multicollinearity(data[common_predictors])

    # Fit and visualise an unadjusted model (symptomatic binary only)
    fit_and_visualise_logistic_regression(data, ['symptomatic_binary'], 'progressed_binary', output_dir, 'unadjusted')

    # Fit and visualise the fully adjusted model (all predictors)
    fit_and_visualise_logistic_regression(data, common_predictors, 'progressed_binary', output_dir, 'adjusted')

# Execute the main function if this script is run directly
if __name__ == '__main__':
    main()
